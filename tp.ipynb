{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EM54mpHhLjIk"
      },
      "source": [
        "[![Supervision](https://media.roboflow.com/open-source/supervision/rf-supervision-banner.png?updatedAt=1678995927529)](https://github.com/roboflow/supervision)\n",
        "\n",
        "# Supervision Quickstart\n",
        "\n",
        "---\n",
        "\n",
        "[![version](https://badge.fury.io/py/supervision.svg)](https://badge.fury.io/py/supervision)\n",
        "[![downloads](https://img.shields.io/pypi/dm/supervision)](https://pypistats.org/packages/supervision)\n",
        "[![license](https://img.shields.io/pypi/l/supervision)](https://github.com/roboflow/supervision/blob/main/LICENSE.md)\n",
        "[![python-version](https://img.shields.io/pypi/pyversions/supervision)](https://badge.fury.io/py/supervision)\n",
        "[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/roboflow/supervision)\n",
        "\n",
        "We write your reusable computer vision tools. Whether you need to load your dataset from your hard drive, draw detections on an image or video, or count how many detections are in a zone. You can count on us! ü§ù\n",
        "\n",
        "We hope that the resources in this notebook will help you get the most out of Supervision. Please browse the Supervision [Docs](https://roboflow.github.io/supervision/) for details, raise an [issue](https://github.com/roboflow/supervision/issues) on GitHub for support, and join our [discussions](https://github.com/roboflow/supervision/discussions) section for questions!\n",
        "\n",
        "## Table of contents\n",
        "\n",
        "- Before you start\n",
        "- Install\n",
        "- Detection API\n",
        "    - Plug in your model\n",
        "        - YOLO-NAS\n",
        "        - YOLOv8\n",
        "    - Annotate\n",
        "        - `BoxAnnotator`, `LabelAnnotator`\n",
        "        - `MaskAnnotator`\n",
        "    - Filter\n",
        "        - By index, index list and index slice\n",
        "        - By `class_id`\n",
        "        - By `confidence`\n",
        "        - By advanced logical condition\n",
        "- Video API\n",
        "    - `VideoInfo`\n",
        "    - `get_video_frames_generator`\n",
        "    - `VideoSink`\n",
        "- Dataset API\n",
        "    - `DetectionDataset.from_yolo`\n",
        "    - Visualize annotations\n",
        "    - `split`\n",
        "    - `DetectionDataset.as_pascal_voc`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qko8PawxQVoS"
      },
      "source": [
        "## ‚ö° Before you start\n",
        "\n",
        "**NOTE:** In this notebook, we aim to show - among other things - how simple it is to integrate `supervision` with popular object detection and instance segmentation libraries and frameworks. GPU access is optional but will certainly make the ride smoother.\n",
        "\n",
        "<br>\n",
        "\n",
        "Let's make sure that we have access to GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `GPU`, and then click `Save`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Pwtk-9CQWsH"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9ZN87GAnqxm"
      },
      "source": [
        "**NOTE:** To make it easier for us to manage datasets, images and models we create a `HOME` constant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwGOFWdJnr3T"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6a80OsDrJ1y"
      },
      "source": [
        "**NOTE:** During our demo, we will need some example images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1oeBxRj5wOv7"
      },
      "outputs": [],
      "source": [
        "!mkdir {HOME}/images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGSeabT2wfQi"
      },
      "source": [
        "**NOTE:** Feel free to use your images. Just make sure to put them into `images` directory that we just created. ‚òùÔ∏è"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDC5HwaXwUyl",
        "outputId": "e669fe2b-6c1e-4ad1-aead-63dd5304049b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu Jul 11 20:48:14 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   72C    P0              32W /  70W |    473MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n",
            "/content/datasets/images\n",
            "/content/datasets/images/images\n"
          ]
        }
      ],
      "source": [
        "%cd {HOME}/images\n",
        "\n",
        "!wget -q https://media.roboflow.com/notebooks/examples/dog.jpeg\n",
        "!wget -q https://media.roboflow.com/notebooks/examples/dog-2.jpeg\n",
        "!wget -q https://media.roboflow.com/notebooks/examples/dog-3.jpeg\n",
        "!wget -q https://media.roboflow.com/notebooks/examples/dog-4.jpeg\n",
        "!wget -q https://media.roboflow.com/notebooks/examples/dog-5.jpeg\n",
        "!wget -q https://media.roboflow.com/notebooks/examples/dog-6.jpeg\n",
        "!wget -q https://media.roboflow.com/notebooks/examples/dog-7.jpeg\n",
        "!wget -q https://media.roboflow.com/notebooks/examples/dog-8.jpeg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hKaZ9NuMofm"
      },
      "source": [
        "## ‚Äçüíª Install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lo8hLtZ2LPWp"
      },
      "outputs": [],
      "source": [
        "!pip install -q supervision\n",
        "\n",
        "import supervision as sv\n",
        "\n",
        "print(sv.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MSBh8-tYuHP"
      },
      "source": [
        "## üëÅÔ∏è Detection API\n",
        "\n",
        "- xyxy `(np.ndarray)`: An array of shape `(n, 4)` containing the bounding boxes coordinates in format `[x1, y1, x2, y2]`\n",
        "- mask: `(Optional[np.ndarray])`: An array of shape `(n, W, H)` containing the segmentation masks.\n",
        "- confidence `(Optional[np.ndarray])`: An array of shape `(n,)` containing the confidence scores of the detections.\n",
        "- class_id `(Optional[np.ndarray])`: An array of shape `(n,)` containing the class ids of the detections.\n",
        "- tracker_id `(Optional[np.ndarray])`: An array of shape `(n,)` containing the tracker ids of the detections."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNKUkCHQchnb"
      },
      "source": [
        "### üîå Plug in your model\n",
        "\n",
        "**NOTE:** In our example, we will focus only on integration with YOLO-NAS and YOLOv8. However, keep in mind that supervision allows seamless integration with many other models like SAM, Transformers, and YOLOv5. You can learn more from our [documentation](https://roboflow.github.io/supervision/detection/core/#detections)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ZlmuEpwydTu"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "IMAGE_PATH = f\"{HOME}/images/dog.jpeg\"\n",
        "\n",
        "image = cv2.imread(IMAGE_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6FgJfB1oIll"
      },
      "source": [
        "### YOLO-NAS [üìö](https://roboflow.github.io/supervision/detection/core/#supervision.detection.core.Detections.from_yolo_nas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-q_XWoIOJgL",
        "outputId": "bbff96b6-f1dd-41af-e32f-42b37a208bb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.21.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -q super-gradients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNcKtoW63g96",
        "outputId": "bf7dbb2c-44b2-45d7-bed3-715d0dfac0a2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[2024-07-11 20:48:37] WARNING - checkpoint_utils.py - :warning: The pre-trained models provided by SuperGradients may have their own licenses or terms and conditions derived from the dataset used for pre-training.\n",
            " It is your responsibility to determine whether you have permission to use the models for your use case.\n",
            " The model you have requested was pre-trained on the coco dataset, published under the following terms: https://cocodataset.org/#termsofuse\n",
            "[2024-07-11 20:48:37] INFO - checkpoint_utils.py - License Notification: YOLO-NAS pre-trained weights are subjected to the specific license terms and conditions detailed in \n",
            "https://github.com/Deci-AI/super-gradients/blob/master/LICENSE.YOLONAS.md\n",
            "By downloading the pre-trained weight files you agree to comply with these terms.\n",
            "[2024-07-11 20:48:38] INFO - checkpoint_utils.py - Successfully loaded pretrained weights for architecture yolo_nas_l\n",
            "[2024-07-11 20:48:38] INFO - pipelines.py - Fusing some of the model's layers. If this takes too much memory, you can deactivate it by setting `fuse_model=False`\n"
          ]
        }
      ],
      "source": [
        "from super_gradients.training import models\n",
        "\n",
        "model = models.get(\"yolo_nas_l\", pretrained_weights=\"coco\")\n",
        "result = model.predict(image)\n",
        "detections = sv.Detections.from_yolo_nas(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdOW9a0P30ar",
        "outputId": "a42af3af-b616-4015-90f9-5f6d11e29ecb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('detections', 7)"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"detections\", len(detections)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOQdWaHDoNyw"
      },
      "source": [
        "### Ultralytics [üìö](https://roboflow.github.io/supervision/detection/core/#supervision.detection.core.Detections.from_ultralytics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNU2p-FYoPbg"
      },
      "outputs": [],
      "source": [
        "!pip install -q ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMx3oMPh1fui",
        "outputId": "530b0cf8-d792-4723-b2f3-a6cb3d677344"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m.pt to 'yolov8m.pt'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0.00/49.7M [00:00<?, ?B/s]\r 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 29.1M/49.7M [00:00<00:00, 305MB/s]\r100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 49.7M/49.7M [00:00<00:00, 363MB/s]\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(\"yolov8m.pt\")\n",
        "result = model(image, verbose=False)[0]\n",
        "detections = sv.Detections.from_ultralytics(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQq5s2ib2bIB",
        "outputId": "49ced652-6b1e-42a8-abae-6f031795b103"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('detections', 4)"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"detections\", len(detections)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wQrUSi-zjmFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import supervision as sv\n",
        "\n",
        "generator = sv.get_video_frames_generator(MALL_VIDEO_PATH)\n",
        "iterator = iter(generator)\n",
        "frame = next(iterator)\n",
        "\n",
        "results = model(frame, image=1280)[0]\n",
        "detections = detections = sv.Detections.from_ultralytics(result)"
      ],
      "metadata": {
        "id": "Au3bpPnRjm1Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}