{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EM54mpHhLjIk"
      },
      "source": [
        "[![Supervision](https://media.roboflow.com/open-source/supervision/rf-supervision-banner.png?updatedAt=1678995927529)](https://github.com/roboflow/supervision)\n",
        "\n",
        "# Supervision Quickstart\n",
        "\n",
        "---\n",
        "\n",
        "[![version](https://badge.fury.io/py/supervision.svg)](https://badge.fury.io/py/supervision)\n",
        "[![downloads](https://img.shields.io/pypi/dm/supervision)](https://pypistats.org/packages/supervision)\n",
        "[![license](https://img.shields.io/pypi/l/supervision)](https://github.com/roboflow/supervision/blob/main/LICENSE.md)\n",
        "[![python-version](https://img.shields.io/pypi/pyversions/supervision)](https://badge.fury.io/py/supervision)\n",
        "[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/roboflow/supervision)\n",
        "\n",
        "We write your reusable computer vision tools. Whether you need to load your dataset from your hard drive, draw detections on an image or video, or count how many detections are in a zone. You can count on us! ğŸ¤\n",
        "\n",
        "We hope that the resources in this notebook will help you get the most out of Supervision. Please browse the Supervision [Docs](https://roboflow.github.io/supervision/) for details, raise an [issue](https://github.com/roboflow/supervision/issues) on GitHub for support, and join our [discussions](https://github.com/roboflow/supervision/discussions) section for questions!\n",
        "\n",
        "## Table of contents\n",
        "\n",
        "- Before you start\n",
        "- Install\n",
        "- Detection API\n",
        "    - Plug in your model\n",
        "        - YOLO-NAS\n",
        "        - YOLOv8\n",
        "    - Annotate\n",
        "        - `BoxAnnotator`, `LabelAnnotator`\n",
        "        - `MaskAnnotator`\n",
        "    - Filter\n",
        "        - By index, index list and index slice\n",
        "        - By `class_id`\n",
        "        - By `confidence`\n",
        "        - By advanced logical condition\n",
        "- Video API\n",
        "    - `VideoInfo`\n",
        "    - `get_video_frames_generator`\n",
        "    - `VideoSink`\n",
        "- Dataset API\n",
        "    - `DetectionDataset.from_yolo`\n",
        "    - Visualize annotations\n",
        "    - `split`\n",
        "    - `DetectionDataset.as_pascal_voc`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qko8PawxQVoS"
      },
      "source": [
        "## âš¡ Before you start\n",
        "\n",
        "**NOTE:** In this notebook, we aim to show - among other things - how simple it is to integrate `supervision` with popular object detection and instance segmentation libraries and frameworks. GPU access is optional but will certainly make the ride smoother.\n",
        "\n",
        "<br>\n",
        "\n",
        "Let's make sure that we have access to GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `GPU`, and then click `Save`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1Pwtk-9CQWsH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4821368-dcd5-4d20-b434-7c5bf2ae7914"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Mar 19 20:46:29 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9ZN87GAnqxm"
      },
      "source": [
        "**NOTE:** To make it easier for us to manage datasets, images and models we create a `HOME` constant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dwGOFWdJnr3T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "234a14b8-8421-436b-eec9-5bb158d9cedd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "HOME = os.getcwd()\n",
        "print(HOME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6a80OsDrJ1y"
      },
      "source": [
        "**NOTE:** During our demo, we will need some example images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1oeBxRj5wOv7"
      },
      "outputs": [],
      "source": [
        "!mkdir {HOME}/images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGSeabT2wfQi"
      },
      "source": [
        "**NOTE:** Feel free to use your images. Just make sure to put them into `images` directory that we just created. â˜ï¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDC5HwaXwUyl",
        "outputId": "39a93cb9-9977-4114-f214-8edcd7b8811a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/images\n"
          ]
        }
      ],
      "source": [
        "%cd {HOME}/images\n",
        "\n",
        "!wget -q https://media.roboflow.com/notebooks/examples/dog.jpeg\n",
        "!wget -q https://media.roboflow.com/notebooks/examples/dog-2.jpeg\n",
        "!wget -q https://media.roboflow.com/notebooks/examples/dog-3.jpeg\n",
        "!wget -q https://media.roboflow.com/notebooks/examples/dog-4.jpeg\n",
        "!wget -q https://media.roboflow.com/notebooks/examples/dog-5.jpeg\n",
        "!wget -q https://media.roboflow.com/notebooks/examples/dog-6.jpeg\n",
        "!wget -q https://media.roboflow.com/notebooks/examples/dog-7.jpeg\n",
        "!wget -q https://media.roboflow.com/notebooks/examples/dog-8.jpeg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hKaZ9NuMofm"
      },
      "source": [
        "## â€ğŸ’» Install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Lo8hLtZ2LPWp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "257f3ec5-21c5-458c-ecdc-c0eb92040eb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/181.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m181.5/181.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h0.25.1\n"
          ]
        }
      ],
      "source": [
        "!pip install -q supervision\n",
        "\n",
        "import supervision as sv\n",
        "\n",
        "print(sv.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MSBh8-tYuHP"
      },
      "source": [
        "## ğŸ‘ï¸ Detection API\n",
        "\n",
        "- xyxy `(np.ndarray)`: An array of shape `(n, 4)` containing the bounding boxes coordinates in format `[x1, y1, x2, y2]`\n",
        "- mask: `(Optional[np.ndarray])`: An array of shape `(n, W, H)` containing the segmentation masks.\n",
        "- confidence `(Optional[np.ndarray])`: An array of shape `(n,)` containing the confidence scores of the detections.\n",
        "- class_id `(Optional[np.ndarray])`: An array of shape `(n,)` containing the class ids of the detections.\n",
        "- tracker_id `(Optional[np.ndarray])`: An array of shape `(n,)` containing the tracker ids of the detections."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNKUkCHQchnb"
      },
      "source": [
        "### ğŸ”Œ Plug in your model\n",
        "\n",
        "**NOTE:** In our example, we will focus only on integration with YOLO-NAS and YOLOv8. However, keep in mind that supervision allows seamless integration with many other models like SAM, Transformers, and YOLOv5. You can learn more from our [documentation](https://roboflow.github.io/supervision/detection/core/#detections)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "0ZlmuEpwydTu"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "IMAGE_PATH = f\"{HOME}/images/dog.jpeg\"\n",
        "VIDEO_PATH = f\"{HOME}/videos/quintanegra.mp4\"\n",
        "\n",
        "image = cv2.imread(IMAGE_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOQdWaHDoNyw"
      },
      "source": [
        "### Ultralytics [ğŸ“š](https://roboflow.github.io/supervision/detection/core/#supervision.detection.core.Detections.from_ultralytics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "gNU2p-FYoPbg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3616809-806a-4e55-9a90-bb0d1f249d5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m949.3/949.3 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m95.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMx3oMPh1fui",
        "outputId": "e235653c-94a3-481f-d9d3-0acac5a1bbff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8m.pt to 'yolov8m.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 49.7M/49.7M [00:00<00:00, 106MB/s]\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO(\"yolov8m.pt\")\n",
        "result = model(image, verbose=False)[0]\n",
        "detections = sv.Detections.from_ultralytics(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "qwsXtjeWnwFa",
        "outputId": "8df10baf-9d50-4490-ba99-b1d34536cace"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 736x1280 2 cars, 1 motorcycle, 82.3ms\n",
            "Speed: 4.4ms preprocess, 82.3ms inference, 2.4ms postprocess per image at shape (1, 3, 736, 1280)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'supervision' has no attribute 'show_frame_in_notebook'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-9b26c526e596>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdetections_segmentation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDetections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_ultralytics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0msv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_frame_in_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: module 'supervision' has no attribute 'show_frame_in_notebook'"
          ]
        }
      ],
      "source": [
        "model = YOLO(\"yolov8m-seg.pt\")\n",
        "\n",
        "generator = sv.get_video_frames_generator(VIDEO_PATH)\n",
        "iterator = iter(generator)\n",
        "frame = next(iterator)\n",
        "\n",
        "result = model(frame, imgsz=1280)[0]\n",
        "detections_segmentation = sv.Detections.from_ultralytics(result)\n",
        "\n",
        "sv.plot_image(frame, (16, 16))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQq5s2ib2bIB",
        "outputId": "50df585e-89e4-45c6-8afb-7750908b36d9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('detections', 4)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "\"detections\", len(detections)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}